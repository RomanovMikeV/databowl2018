{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import trainer\n",
    "import dataset_masker as dataset\n",
    "import skimage.transform\n",
    "import model_masker as model\n",
    "\n",
    "import utils\n",
    "\n",
    "anchors = [[1.0, 1.0]]\n",
    "mask_size = [15, 15]\n",
    "\n",
    "train_dataset = dataset.DataSet('../data/', mode='train', anchors=anchors, mask_size=mask_size)\n",
    "valid_dataset = dataset.DataSet('../data/', mode='valid', anchors=anchors, mask_size=mask_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic collator function\n",
    "def my_collator(args):\n",
    "    res = None\n",
    "    for arg in args:\n",
    "        if res is None:\n",
    "            res = []\n",
    "            for item in arg:\n",
    "                res.append([])\n",
    "        for index in range(len(arg)):\n",
    "            res[index].append(arg[index])\n",
    "    \n",
    "    return res\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=4, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2,\n",
    "                                           drop_last=True,)\n",
    "#                                            collate_fn=my_collator)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2,\n",
    "                                           drop_last=False,)\n",
    "#                                            collate_fn=my_collator)\n",
    "\n",
    "net = model.Network(len(anchors), mask_size).float().cuda()\n",
    "input = torch.autograd.Variable(torch.zeros(10, 3, 128, 128).float().cuda())\n",
    "result = net.forward([input])\n",
    "\n",
    "\n",
    "socket = model.Socket(net, anchors)\n",
    "\n",
    "pretrain_modules = torch.nn.ModuleList([socket.model.up_bn1, \n",
    "                                        socket.model.up_bn2, \n",
    "                                        socket.model.up_bn3,\n",
    "                                        socket.model.up1, \n",
    "                                        socket.model.up2, \n",
    "                                        socket.model.up3,\n",
    "                                        socket.model.detector]).parameters()\n",
    "# train_moduels = net.parameters()\n",
    "\n",
    "pretrain_optimizer = torch.optim.Adam(pretrain_modules, lr=3.0e-4)\n",
    "my_pretrainer = trainer.Trainer(socket, pretrain_optimizer)\n",
    "\n",
    "for index in range(1000):\n",
    "#     print(\"Epoch\", index)\n",
    "    print(\"Epoch\", index)\n",
    "    print(\"Training ... \", end='')\n",
    "    loss = my_pretrainer.train(train_loader)\n",
    "    print(\"Done\")\n",
    "    print(\"Validating ... \", end='')\n",
    "    train_metrics = my_pretrainer.validate(train_loader)\n",
    "    valid_metrics = my_pretrainer.validate(valid_loader)\n",
    "    print(\"Done\")\n",
    "    print('; '.join([str(x) for x in train_metrics + valid_metrics]))\n",
    "    \n",
    "#     my_pretrainer.validate()\n",
    "\n",
    "my_pretrainer.make_checkpoint('checkpoint_pretrained.t7')\n",
    "\n",
    "train_modules = socket.model.parameters()\n",
    "\n",
    "train_optimizer = torch.optim.Adam(train_modules, lr=3.0e-4)\n",
    "my_trainer = trainer.Trainer(socket, train_optimizer)\n",
    "\n",
    "for index in range(1000):\n",
    "#     print(\"Epoch\", index)\n",
    "    print(\"Epoch\", index)\n",
    "    print(\"Training ... \", end='')\n",
    "    loss = my_pretrainer.train(train_loader)\n",
    "    print(\"Done\")\n",
    "    print(\"Validating ... \", end='')\n",
    "    train_metrics = my_pretrainer.validate(train_loader)\n",
    "    valid_metrics = my_pretrainer.validate(valid_loader)\n",
    "    print(\"Done\")\n",
    "    print('; '.join([str(x) for x in train_metrics + valid_metrics]))\n",
    "\n",
    "my_trainer.make_checkpoint('checkpoint.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(bbox1, bbox2):\n",
    "    left = max(bbox1[0], bbox2[0])\n",
    "    top = max(bbox1[1], bbox2[1])\n",
    "    right = min(bbox1[2], bbox2[2])\n",
    "    bottom = min(bbox1[3], bbox2[3])\n",
    "    \n",
    "    intersection = max((right - left) * (top - bottom), 0)\n",
    "    union = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])\n",
    "    union += (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "\n",
    "# Дальше надо сделать формирование таргета и начинать обучение при помощи тренера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    for res in train_loader:\n",
    "        print(res)\n",
    "        break\n",
    "#         print(batch)\n",
    "        #print(images)\n",
    "        print(targets[0], '<- bboxes')\n",
    "        print(targets[1], '<- masks')\n",
    "#         print(targets[2], '<- wtf')\n",
    "#         print(targets, '<- targets')\n",
    "        break\n",
    "    break\n",
    "#         print(len(images), len(targets), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "def plotter(img, masks, alpha=0.5):\n",
    "#     figure(figsize=(20, 20))\n",
    "    imshow(img)\n",
    "    print(img.shape)\n",
    "    overlay = numpy.zeros(img.shape[:2] + (4,))\n",
    "    overlay[:, :, 0] = 1.0\n",
    "    \n",
    "    for mask in masks:\n",
    "        bbox = mask[0]\n",
    "        \n",
    "        left = round(bbox[0] * (img.shape[0] - 1))\n",
    "        top = round(bbox[1] * (img.shape[1] - 1))\n",
    "        right = round(bbox[2] * (img.shape[0] - 1))\n",
    "        bottom = round(bbox[3] * (img.shape[1] - 1))\n",
    "        \n",
    "#         print(mask[1])\n",
    "        if (right - left) < 0.5 or (bottom - top) < 0.5:\n",
    "            continue\n",
    "        mask_tensor = skimage.transform.resize(\n",
    "            mask[1], \n",
    "            [round(right) - round(left) + 1, round(bottom) - round(top) + 1], \n",
    "            mode='reflect')\n",
    "        \n",
    "        plot([top, top], [left, right + 1], 'r')\n",
    "        plot([bottom + 1, bottom + 1], [left, right + 1], 'r')\n",
    "        plot([top, bottom + 1], [left, left], 'r')\n",
    "        plot([top, bottom + 1], [right + 1, right + 1], 'r')\n",
    "        \n",
    "        overlay[round(left):round(right) + 1, \n",
    "                round(top):round(bottom) + 1, 3] = mask_tensor * alpha\n",
    "        \n",
    "    imshow(overlay)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "my_dataset = dataset.DataSet('../data/')\n",
    "print(len(my_dataset))\n",
    "\n",
    "index = 0\n",
    "while True:\n",
    "    index += 1\n",
    "    print(index, len(my_dataset), end=' ')\n",
    "    if index >= len(my_dataset):\n",
    "        index = 0\n",
    "    \n",
    "    img, masks = my_dataset[index]\n",
    "    \n",
    "    if img.size(1) != 112:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
